	I believe that AI can be a good tool for all of the lower-level tasks, such as transportation, tracking human health, production, etc. However, when AI comes into the higher-level influence, such as monitoring the internet signal such as search history and social media for social security, or for personalizing entertainment, it requires deeper caution about the progress of how  AI prediction tools shape our human thought, providing interest-driven rather than quality-driven information, and offend privacy. 
	In the report, the author believes that “well-deployed AI prediction tools have the potential to actually remove or reduce human bias, rather than reinforcing it, and research and resources should be directed toward ensuring this effect”. For example, “AI can help in social network analysis to prevent those at risk from being radicalized by ISIS or other violent groups”. However,  in most normal cases for a general public user, the process of personalization will shape human thought imperceptibly. Shaping is “the production of new forms of operant behavior by reinforcement of successive approximations to the behavior” (APA). We might get more biased and reinforce our own beliefs while we review more similar information form online due to personalization. The report points out that AI helps “social networks such as Facebook are now pervasive, and they function as personalized channels of social interaction and entertainment”. This means that Facebook will track the user's view history, how much time they spend on each piece of news, information, or topics, and likes or comments. After this personalization algorithm calculation, the user will get more and more information that they like. For example, when Facebook notices you liked the democrat view, your republican friends’ posts will disappear (Pariser, 2011). This personalized “online filter bubble” will shape our own beliefs to more extreme since we were told that the world believes the same thing as me, which creates even more bias. More importantly, it might be used to shape our thought, which can influence our decision, such as an election. 
	Moreover, other than Facebook, Google search engine results “are sorted not only by objective relevance, but rather are heavily influenced by your search history, your social network, when you are searching, and where you are searching from” (Holone, 2016). “The problem is the invisibility of the algorithms, both in terms of the way they are hidden from explicit view on search engines, and social networks and the way they directly impact the quality of the information we find when we look for information online” (Holone, 2016). In addition to the bias that people get from personalized search results, when the search comes to health information, personalization algorithms AI prediction tools are unable to jump out from the human bias and provide high-quality information. Since the user is searching for health information, which might cause serious results. 
	Meanwhile, The AI prediction tool is tracking over 200 different signals from how people use the internet (Holone, 2016). The monitoring and personalization reflect the issue of the privacy of individuals. 