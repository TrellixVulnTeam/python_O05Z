{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "#These first two functions require os operations and so are completed for you\n",
    "#Completed for you\n",
    "def load_training_data(vocab, directory):\n",
    "    \"\"\" Create the list of dictionaries \"\"\"\n",
    "    top_level = os.listdir(directory)\n",
    "    dataset = []\n",
    "    for d in top_level:\n",
    "        if d[-1] == '/':\n",
    "            label = d[:-1]\n",
    "            subdir = d\n",
    "        else:\n",
    "            label = d\n",
    "            subdir = d+\"/\"\n",
    "        files = os.listdir(directory+subdir)\n",
    "        for f in files:\n",
    "            bow = create_bow(vocab, directory+subdir+f)\n",
    "            dataset.append({'label': label, 'bow': bow})\n",
    "    return dataset\n",
    "\n",
    "#Completed for you\n",
    "def create_vocabulary(directory, cutoff):\n",
    "    \"\"\" Create a vocabulary from the training directory\n",
    "        return a sorted vocabulary list\n",
    "    \"\"\"\n",
    "\n",
    "    top_level = os.listdir(directory)\n",
    "    vocab = {}\n",
    "    for d in top_level:\n",
    "        subdir = d if d[-1] == '/' else d+'/'\n",
    "        files = os.listdir(directory+subdir)\n",
    "        for f in files:\n",
    "            with open(directory+subdir+f,'r',encoding=\"utf-8\") as doc:\n",
    "                for word in doc:\n",
    "                    word = word.strip()\n",
    "                    if not word in vocab and len(word) > 0:\n",
    "                        vocab[word] = 1\n",
    "                    elif len(word) > 0:\n",
    "                        vocab[word] += 1\n",
    "    return sorted([word for word in vocab if vocab[word] >= cutoff])\n",
    "\n",
    "#The rest of the functions need modifications ------------------------------\n",
    "#Needs modifications\n",
    "def create_bow(vocab, filepath):\n",
    "    \"\"\" Create a single dictionary for the data\n",
    "        Note: label may be None\n",
    "    \"\"\"\n",
    "    bow = {}\n",
    "    with open(filepath,encoding=\"utf-8\") as doc:\n",
    "        for word in doc:\n",
    "            word = word.strip()\n",
    "            if word not in vocab:\n",
    "                if None not in bow: \n",
    "                    bow[None]=1\n",
    "                else:\n",
    "                    bow[None] +=1\n",
    "            if not word in bow and word in vocab:\n",
    "                bow[word] = 1\n",
    "            elif word in vocab:\n",
    "                bow[word] += 1\n",
    "    return bow\n",
    "\n",
    "#Needs modifications\n",
    "def prior(training_data, label_list):\n",
    "    \"\"\" return the prior probability of the label in the training set\n",
    "        => frequency of DOCUMENTS\n",
    "    \"\"\"\n",
    "    smooth = 1 # smoothing factor\n",
    "    logprob = {}\n",
    "    count={}\n",
    "    for i in label_list:\n",
    "        count[i]=0\n",
    "    for doc in training_data:\n",
    "        if doc[\"label\"] == label_list[0]:\n",
    "            count[label_list[0]]+=1\n",
    "        else:\n",
    "            count[label_list[1]]+=1\n",
    "    total=0\n",
    "    for i in count:\n",
    "        total+=count[i]\n",
    "    for i in count:\n",
    "        logprob[i]=math.log((count[i]+smooth)/(total+2))\n",
    "\n",
    "    return logprob\n",
    "\n",
    "# def prior(training_data, label_list):\n",
    "#     \"\"\" return the prior probability of the label in the training set\n",
    "#         => frequency of DOCUMENTS\n",
    "#     \"\"\"\n",
    "#     smooth = 1 # smoothing factor\n",
    "#     logprob = {}\n",
    "#     count={\"2016\":0,\"2020\":0}\n",
    "#     for doc in training_data:\n",
    "#         if doc[\"label\"]== \"2016\":\n",
    "#             count[\"2016\"]+=1\n",
    "#         else:\n",
    "#             count[\"2020\"]+=1\n",
    "#     total= count[\"2016\"]+count[\"2020\"]\n",
    "#     for i in count:\n",
    "#         logprob[i]=ln((count[i]+smooth)/(total+2))\n",
    "\n",
    "#     return logprob\n",
    "\n",
    "#Needs modifications\n",
    "def p_word_given_label(vocab, training_data, label):\n",
    "    \"\"\" return the class conditional probability of label over all words, with smoothing \"\"\"\n",
    "    smooth = 1 # smoothing factor\n",
    "    word_prob = {}\n",
    "    for i in vocab: \n",
    "        word_prob[i]=0\n",
    "    total=0\n",
    "    word_prob[None]=0\n",
    "    for i in training_data:\n",
    "        if i[\"label\"]== label:\n",
    "            for word in i[\"bow\"]:\n",
    "                total+=i[\"bow\"][word]\n",
    "                if word in vocab:\n",
    "                    word_prob[word] += i[\"bow\"][word]\n",
    "                else:\n",
    "                    word_prob[None]+=i[\"bow\"][word]\n",
    "    for i in word_prob:\n",
    "        word_prob[i]=math.log((word_prob[i]+smooth)/(total+len(vocab)+1))\n",
    "    return word_prob\n",
    "\n",
    "\n",
    "##################################################################################\n",
    "#Needs modifications\n",
    "def train(training_directory, cutoff):\n",
    "    \"\"\" return a dictionary formatted as follows:\n",
    "            {\n",
    "             'vocabulary': <the training set vocabulary>,\n",
    "             'log prior': <the output of prior()>,\n",
    "             'log p(w|y=2016)': <the output of p_word_given_label() for 2016>,\n",
    "             'log p(w|y=2020)': <the output of p_word_given_label() for 2020>\n",
    "            }\n",
    "    \"\"\"\n",
    "    retval = {}\n",
    "    label_list = os.listdir(training_directory)\n",
    "    vocab=create_vocabulary(training_directory, cutoff)\n",
    "    training_data=load_training_data(vocab, training_directory)\n",
    "    retval['vocabulary']=vocab\n",
    "    retval['log prior']=prior(training_data,label_list)\n",
    "    retval['p(w|y=2016)']= p_word_given_label(vocab, training_data, '2016')\n",
    "    retval['p(w|y=2020)']= p_word_given_label(vocab, training_data, '2020')\n",
    "    return retval\n",
    "\n",
    "#Needs modifications\n",
    "def classify(model, filepath):\n",
    "    retval = {}\n",
    "    year2016=model[\"log prior\"][\"2016\"]\n",
    "    year2020=model[\"log prior\"][\"2020\"]\n",
    "    bow = create_bow(model[\"vocabulary\"], filepath)\n",
    "    for i in bow:\n",
    "        year2016+=model[\"p(w|y=2016)\"][i]*bow[i]\n",
    "        year2020+=model[\"p(w|y=2020)\"][i]*bow[i]\n",
    "    retval[\"log p(y=2016|x)\"]=year2016\n",
    "    retval[\"log p(y=2020|x)\"]=year2020\n",
    "    if max(year2016,year2020)==year2016:\n",
    "        retval['predicted y']=\"2016\"\n",
    "    else:\n",
    "        retval['predicted y']=\"2020\"\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 2, 'dog': 1, 'chases': 1, 'cat': 1, '.': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v=create_vocabulary('./EasyFiles/', 1)\n",
    "load_training_data(v,'./EasyFiles/')\n",
    "create_bow(v,'./EasyFiles/2016/1.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'log p(y=2016|x)': -3916.458747858928,\n",
       " 'log p(y=2020|x)': -3906.351945884106,\n",
       " 'predicted y': '2020'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = create_vocabulary('./corpus/training/', 2)\n",
    "training_data = load_training_data(vocab,'./corpus/training/')\n",
    "prior(training_data, ['2020', '2016'])\n",
    "p_word_given_label(vocab, training_data, '2016')\n",
    "model=train('./corpus/training/', 2)\n",
    "classify(model, './corpus/test/2016/0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
